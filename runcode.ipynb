{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.models import resnet34, resnet18\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "import torch.optim as optim\n",
    "# from torchsummaryX import summary\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,backbone=resnet34,pretrained=True,last_size=512,num_classes=2):\n",
    "        super().__init__()\n",
    "        self.model = backbone(pretrained=pretrained)\n",
    "        self.model.fc = nn.Linear(last_size,num_classes)\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "        \n",
    "        \n",
    "\n",
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self, filepath, train=False,test_size=0.1, seed=12345, transform=None):\n",
    "#         self.imges_filepaths = glob.glob(os.path.join(filepath,'/**/*.jpg'))\n",
    "        self.classes = next(iter(os.walk(filepath)))[1]\n",
    "        imgs, labels = [], []\n",
    "        for i,cl in enumerate(self.classes):\n",
    "            findpath = os.path.join(filepath,f'{cl}/','*.jpg')\n",
    "            current_imgs = glob.glob(findpath)\n",
    "            imgs += current_imgs\n",
    "            labels += [i for _ in current_imgs]\n",
    "        img_train, img_test, label_train, label_test = train_test_split(imgs, labels, test_size=test_size,\n",
    "                                                                        random_state=seed)\n",
    "        if train:\n",
    "            self.imgs = img_train\n",
    "            self.labels = label_train\n",
    "        else:\n",
    "            self.imgs = img_test\n",
    "            self.labels = label_test\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.imgs[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting variables\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "train_batch_size = 128\n",
    "val_batch_size = 32\n",
    "rate_learning = 1e-3\n",
    "net = Net()\n",
    "# net = Net(in_channels=3, num_classes=10)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "\n",
    "seed = 123451\n",
    "\n",
    "transform_train = A.Compose(\n",
    "    [\n",
    "        A.SmallestMaxSize(max_size=256),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "        A.RandomCrop(height=224, width=224),\n",
    "        A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_val = A.Compose(\n",
    "    [\n",
    "        A.SmallestMaxSize(max_size=224),\n",
    "        A.CenterCrop(height=224, width=224),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "root = './data/catdog/train'\n",
    "trainset = CatDogDataset(root,train=True,test_size=0.1, seed=seed, transform = transform_train)\n",
    "valset = CatDogDataset(root,train=False,test_size=0.1, seed=seed, transform = transform_val)\n",
    "\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=train_batch_size,\n",
    "                         shuffle=True, num_workers=0)\n",
    "valloader = DataLoader(valset, batch_size=val_batch_size,\n",
    "                        shuffle=False, num_workers=0)\n",
    "\n",
    "classes = trainset.classes\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % labels[j].item() for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimizer\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(), lr=rate_learning, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=rate_learning)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(total_epoch):\n",
    "    net.train()\n",
    "    for epoch in range(total_epoch):\n",
    "        with tqdm(trainloader, unit='batch')as tepoch:\n",
    "            tepoch.set_description(f'Epoch [{epoch+1}/{total_epoch}] ')\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "            running_batchsize = 0\n",
    "            for inputs,labels in tepoch:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad() #zero grad 안하면 grad 를 계속 가지고 있는다.\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                predictions = outputs.argmax(dim=1, keepdim=True).squeeze()\n",
    "                running_batchsize += inputs.cpu().detach().shape[0]\n",
    "                running_accuracy += (predictions == labels).sum().item()\n",
    "                running_loss += loss.item()\n",
    "                tepoch.set_postfix(loss=running_loss/running_batchsize, accuracy=running_accuracy/running_batchsize)\n",
    "        test()\n",
    "\n",
    "\n",
    "def test():\n",
    "    net.eval()\n",
    "    with tqdm(valloader, unit='batch')as tepoch:\n",
    "        tepoch.set_description(f'Validation ')\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        running_batchsize = 0\n",
    "        class_correct = {k:0 for k in classes}\n",
    "        class_total = {k:0 for k in classes}\n",
    "        \n",
    "        for inputs,labels in tepoch:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = net(inputs)\n",
    "            loss = criterion(outputs,labels)\n",
    "            predictions = outputs.argmax(dim=1, keepdim=True).squeeze()\n",
    "            running_batchsize += inputs.cpu().detach().shape[0]\n",
    "            running_accuracy += (predictions == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            tepoch.set_postfix(loss=running_loss/running_batchsize, accuracy=running_accuracy/running_batchsize)\n",
    "            \n",
    "            for idx,name in enumerate(classes):\n",
    "                label_idx = (labels == idx)\n",
    "                if label_idx.sum().item() == 0:\n",
    "                    continue\n",
    "                class_correct[name] += labels[label_idx].eq(\n",
    "                    torch.argmax(outputs[label_idx], 1)).sum().item()\n",
    "                class_total[name] += labels[label_idx].size(0)\n",
    "    for name in classes:\n",
    "        print(f'Accuracy of {name}s : {100.*class_correct[name]/class_total[name]:.2f}%')\n",
    "\n",
    "\n",
    "#         print(f'Accuracy : {(100.*correct/total):.3f}')\n",
    "# #         classes = ('plane', 'car', 'bird', 'cat', 'deer', 'doge', 'frog', 'horse', 'ship', 'truck')\n",
    "#         for i in range(10):\n",
    "#             print(f'Accuracy of {classes[i]}s : {100.*class_correct[i]/class_total[i]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
